"""
æ–‡æ¡£åŠ è½½å™¨ - ç”¨äºåŠ è½½å’Œå¤„ç†å„ç§æ ¼å¼çš„æ–‡æ¡£
æ”¯æŒï¼šMarkdown, HTML, çº¯æ–‡æœ¬, JSONç­‰
"""
import os
import logging
import json
from typing import List, Dict, Any, Optional
from pathlib import Path
from dataclasses import dataclass
import re

try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

logger = logging.getLogger(__name__)


@dataclass
class Document:
    """æ–‡æ¡£æ•°æ®ç±»"""
    content: str
    metadata: Dict[str, Any]
    id: Optional[str] = None


class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨åŸºç±»"""

    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        """
        åˆå§‹åŒ–æ–‡æ¡£åŠ è½½å™¨

        Args:
            chunk_size: æ–‡æ¡£åˆ†å—å¤§å°
            chunk_overlap: å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def load(self, source: str) -> List[Document]:
        """
        åŠ è½½æ–‡æ¡£ï¼ˆéœ€è¦å­ç±»å®ç°ï¼‰

        Args:
            source: æ–‡æ¡£æºï¼ˆæ–‡ä»¶è·¯å¾„ã€URLç­‰ï¼‰

        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        raise NotImplementedError

    def chunk_text(self, text: str, metadata: Dict[str, Any]) -> List[Document]:
        """
        å°†é•¿æ–‡æœ¬åˆ†å—

        Args:
            text: åŸå§‹æ–‡æœ¬
            metadata: å…ƒæ•°æ®

        Returns:
            åˆ†å—åçš„æ–‡æ¡£åˆ—è¡¨
        """
        if len(text) <= self.chunk_size:
            return [Document(content=text, metadata=metadata)]

        chunks = []
        start = 0

        while start < len(text):
            end = start + self.chunk_size

            # å°è¯•åœ¨å¥å­è¾¹ç•Œå¤„åˆ†å‰²
            if end < len(text):
                # æŸ¥æ‰¾æœ€è¿‘çš„å¥å·ã€é—®å·æˆ–æ¢è¡Œç¬¦
                for delimiter in ['\n\n', '\n', '. ', 'ã€‚', '! ', 'ï¼', '? ', 'ï¼Ÿ']:
                    last_delimiter = text.rfind(delimiter, start, end)
                    if last_delimiter != -1:
                        end = last_delimiter + len(delimiter)
                        break

            chunk_text = text[start:end].strip()
            if chunk_text:
                chunk_metadata = metadata.copy()
                chunk_metadata['chunk_index'] = len(chunks)
                chunks.append(Document(
                    content=chunk_text,
                    metadata=chunk_metadata
                ))

            start = end - self.chunk_overlap if end < len(text) else end

        return chunks


class MarkdownLoader(DocumentLoader):
    """Markdownæ–‡æ¡£åŠ è½½å™¨"""

    def load(self, file_path: str) -> List[Document]:
        """åŠ è½½Markdownæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            metadata = {
                'source': file_path,
                'type': 'markdown',
                'filename': Path(file_path).name
            }

            return self.chunk_text(content, metadata)

        except Exception as e:
            logger.error(f"âŒ åŠ è½½Markdownæ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return []


class HTMLLoader(DocumentLoader):
    """HTMLæ–‡æ¡£åŠ è½½å™¨"""

    def load(self, file_path: str) -> List[Document]:
        """åŠ è½½HTMLæ–‡ä»¶"""
        try:
            if BeautifulSoup is None:
                raise ImportError("éœ€è¦å®‰è£…beautifulsoup4: pip install beautifulsoup4")

            with open(file_path, 'r', encoding='utf-8') as f:
                html_content = f.read()

            # ä½¿ç”¨BeautifulSoupè§£æHTML
            soup = BeautifulSoup(html_content, 'html.parser')

            # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
            for script in soup(['script', 'style']):
                script.decompose()

            # æå–æ–‡æœ¬
            text = soup.get_text()

            # æ¸…ç†å¤šä½™çš„ç©ºç™½
            text = re.sub(r'\n\s*\n', '\n\n', text)
            text = text.strip()

            metadata = {
                'source': file_path,
                'type': 'html',
                'filename': Path(file_path).name
            }

            return self.chunk_text(text, metadata)

        except Exception as e:
            logger.error(f"âŒ åŠ è½½HTMLæ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return []


class JSONLoader(DocumentLoader):
    """JSONæ–‡æ¡£åŠ è½½å™¨"""

    def __init__(self, content_key: str = 'content', **kwargs):
        """
        åˆå§‹åŒ–JSONåŠ è½½å™¨

        Args:
            content_key: JSONä¸­åŒ…å«å†…å®¹çš„é”®å
        """
        super().__init__(**kwargs)
        self.content_key = content_key

    def load(self, file_path: str) -> List[Document]:
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            documents = []

            # å¦‚æœæ˜¯åˆ—è¡¨
            if isinstance(data, list):
                for i, item in enumerate(data):
                    content = self._extract_content(item)
                    if content:
                        metadata = {
                            'source': file_path,
                            'type': 'json',
                            'filename': Path(file_path).name,
                            'index': i
                        }
                        documents.extend(self.chunk_text(content, metadata))

            # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡
            elif isinstance(data, dict):
                content = self._extract_content(data)
                if content:
                    metadata = {
                        'source': file_path,
                        'type': 'json',
                        'filename': Path(file_path).name
                    }
                    documents.extend(self.chunk_text(content, metadata))

            return documents

        except Exception as e:
            logger.error(f"âŒ åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return []

    def _extract_content(self, item: Any) -> str:
        """ä»JSONå¯¹è±¡ä¸­æå–å†…å®¹"""
        if isinstance(item, str):
            return item
        elif isinstance(item, dict):
            if self.content_key in item:
                return str(item[self.content_key])
            # å¦‚æœæ²¡æœ‰æŒ‡å®šé”®ï¼Œå°†æ•´ä¸ªå¯¹è±¡è½¬ä¸ºå­—ç¬¦ä¸²
            return json.dumps(item, ensure_ascii=False)
        else:
            return str(item)


class TextLoader(DocumentLoader):
    """çº¯æ–‡æœ¬æ–‡æ¡£åŠ è½½å™¨"""

    def load(self, file_path: str) -> List[Document]:
        """åŠ è½½æ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            metadata = {
                'source': file_path,
                'type': 'text',
                'filename': Path(file_path).name
            }

            return self.chunk_text(content, metadata)

        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ–‡æœ¬æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return []


class DirectoryLoader:
    """ç›®å½•åŠ è½½å™¨ - æ‰¹é‡åŠ è½½ç›®å½•ä¸­çš„æ–‡æ¡£"""

    def __init__(
        self,
        chunk_size: int = 1000,
        chunk_overlap: int = 200
    ):
        """åˆå§‹åŒ–ç›®å½•åŠ è½½å™¨"""
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

        # æ–‡ä»¶æ‰©å±•ååˆ°åŠ è½½å™¨çš„æ˜ å°„
        self.loaders = {
            '.md': MarkdownLoader(chunk_size, chunk_overlap),
            '.markdown': MarkdownLoader(chunk_size, chunk_overlap),
            '.html': HTMLLoader(chunk_size, chunk_overlap),
            '.htm': HTMLLoader(chunk_size, chunk_overlap),
            '.json': JSONLoader(chunk_size=chunk_size, chunk_overlap=chunk_overlap),
            '.txt': TextLoader(chunk_size, chunk_overlap),
        }

    def load(
        self,
        directory: str,
        glob_pattern: str = "**/*",
        exclude_patterns: Optional[List[str]] = None
    ) -> List[Document]:
        """
        åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£

        Args:
            directory: ç›®å½•è·¯å¾„
            glob_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
            exclude_patterns: æ’é™¤çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨

        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        directory_path = Path(directory)
        if not directory_path.exists():
            logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
            return []

        all_documents = []
        exclude_patterns = exclude_patterns or []

        # éå†åŒ¹é…çš„æ–‡ä»¶
        for file_path in directory_path.glob(glob_pattern):
            if not file_path.is_file():
                continue

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
            should_exclude = any(
                re.search(pattern, str(file_path))
                for pattern in exclude_patterns
            )
            if should_exclude:
                continue

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½å™¨
            suffix = file_path.suffix.lower()
            loader = self.loaders.get(suffix)

            if loader:
                logger.info(f"ğŸ“„ åŠ è½½æ–‡ä»¶: {file_path}")
                documents = loader.load(str(file_path))
                all_documents.extend(documents)
            else:
                logger.debug(f"â­ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path}")

        logger.info(f"âœ… ä»ç›®å½• {directory} åŠ è½½äº† {len(all_documents)} ä¸ªæ–‡æ¡£å—")
        return all_documents


class APIDocumentLoader:
    """APIæ–‡æ¡£é¢„ç½®åŠ è½½å™¨ - åŠ è½½å¸¸è§æ¸¸æˆå¼€å‘APIæ–‡æ¡£"""

    @staticmethod
    def load_phaser_docs() -> List[Document]:
        """åŠ è½½Phaseræ¸¸æˆå¼•æ“æ–‡æ¡£ï¼ˆç¤ºä¾‹ï¼‰"""
        # è¿™é‡Œæä¾›ä¸€äº›é¢„ç½®çš„Phaser APIæ–‡æ¡£
        phaser_docs = [
            {
                "content": """
Phaser.Game - æ¸¸æˆä¸»ç±»
åˆ›å»ºä¸€ä¸ªæ–°çš„Phaseræ¸¸æˆå®ä¾‹ã€‚

æ„é€ å‡½æ•°:
new Phaser.Game(config)

é…ç½®å‚æ•°:
- type: Phaser.AUTO, Phaser.CANVAS, æˆ– Phaser.WEBGL
- width: æ¸¸æˆå®½åº¦ï¼ˆåƒç´ ï¼‰
- height: æ¸¸æˆé«˜åº¦ï¼ˆåƒç´ ï¼‰
- scene: åœºæ™¯ç±»æˆ–åœºæ™¯é…ç½®å¯¹è±¡
- physics: ç‰©ç†å¼•æ“é…ç½®
- backgroundColor: èƒŒæ™¯é¢œè‰²

ç¤ºä¾‹:
const config = {
    type: Phaser.AUTO,
    width: 800,
    height: 600,
    scene: {
        preload: preload,
        create: create,
        update: update
    }
};
const game = new Phaser.Game(config);
                """,
                "metadata": {"source": "phaser", "api": "Game", "category": "core"}
            },
            {
                "content": """
Phaser.Scene - åœºæ™¯ç±»
åœºæ™¯æ˜¯æ¸¸æˆçš„ä¸€ä¸ªç‹¬ç«‹éƒ¨åˆ†ï¼ŒåŒ…å«è‡ªå·±çš„èµ„æºã€æ¸¸æˆå¯¹è±¡å’Œé€»è¾‘ã€‚

ç”Ÿå‘½å‘¨æœŸæ–¹æ³•:
- init(data): åˆå§‹åŒ–åœºæ™¯ï¼Œæ¥æ”¶å¯åŠ¨æ•°æ®
- preload(): é¢„åŠ è½½èµ„æº
- create(data): åˆ›å»ºæ¸¸æˆå¯¹è±¡
- update(time, delta): æ¯å¸§æ›´æ–°

åŠ è½½èµ„æº:
this.load.image('key', 'path/to/image.png');
this.load.audio('key', 'path/to/audio.mp3');
this.load.spritesheet('key', 'path/to/spritesheet.png', { frameWidth: 32, frameHeight: 32 });

æ·»åŠ æ¸¸æˆå¯¹è±¡:
this.add.sprite(x, y, 'key');
this.add.text(x, y, 'Hello World', { fontSize: '32px', fill: '#fff' });
                """,
                "metadata": {"source": "phaser", "api": "Scene", "category": "core"}
            },
            {
                "content": """
Phaser.Physics.Arcade - Arcadeç‰©ç†å¼•æ“
ç®€å•ã€å¿«é€Ÿçš„ç‰©ç†å¼•æ“ï¼Œé€‚åˆå¤§å¤šæ•°2Dæ¸¸æˆã€‚

å¯ç”¨ç‰©ç†:
åœ¨æ¸¸æˆé…ç½®ä¸­æ·»åŠ ï¼š
physics: {
    default: 'arcade',
    arcade: {
        gravity: { y: 300 },
        debug: false
    }
}

ç»™æ¸¸æˆå¯¹è±¡æ·»åŠ ç‰©ç†:
this.physics.add.sprite(x, y, 'key');
this.physics.add.existing(gameObject);

è®¾ç½®ç‰©ç†å±æ€§:
sprite.setVelocity(100, 200);
sprite.setBounce(0.2);
sprite.setCollideWorldBounds(true);

ç¢°æ’æ£€æµ‹:
this.physics.add.collider(object1, object2, collisionCallback);
this.physics.add.overlap(object1, object2, overlapCallback);
                """,
                "metadata": {"source": "phaser", "api": "Physics", "category": "physics"}
            }
        ]

        documents = []
        for i, doc_data in enumerate(phaser_docs):
            documents.append(Document(
                content=doc_data["content"].strip(),
                metadata=doc_data["metadata"],
                id=f"phaser_doc_{i}"
            ))

        logger.info(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªPhaseræ–‡æ¡£")
        return documents

    @staticmethod
    def load_canvas_docs() -> List[Document]:
        """åŠ è½½Canvas APIæ–‡æ¡£ï¼ˆç¤ºä¾‹ï¼‰"""
        canvas_docs = [
            {
                "content": """
Canvas API - åŸºç¡€ç»˜å›¾
HTML5 Canvasæä¾›äº†2Dç»˜å›¾APIã€‚

è·å–ä¸Šä¸‹æ–‡:
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');

ç»˜åˆ¶çŸ©å½¢:
ctx.fillRect(x, y, width, height);  // å¡«å……çŸ©å½¢
ctx.strokeRect(x, y, width, height);  // æè¾¹çŸ©å½¢
ctx.clearRect(x, y, width, height);  // æ¸…é™¤çŸ©å½¢åŒºåŸŸ

è®¾ç½®æ ·å¼:
ctx.fillStyle = 'red';  // å¡«å……é¢œè‰²
ctx.strokeStyle = '#00ff00';  // æè¾¹é¢œè‰²
ctx.lineWidth = 5;  // çº¿å®½
                """,
                "metadata": {"source": "canvas", "api": "drawing", "category": "basic"}
            },
            {
                "content": """
Canvas API - è·¯å¾„ç»˜åˆ¶
ä½¿ç”¨è·¯å¾„å¯ä»¥ç»˜åˆ¶å¤æ‚çš„å½¢çŠ¶ã€‚

å¼€å§‹è·¯å¾„:
ctx.beginPath();

ç§»åŠ¨å’Œç»˜åˆ¶:
ctx.moveTo(x, y);  // ç§»åŠ¨åˆ°ç‚¹
ctx.lineTo(x, y);  // ç”»çº¿åˆ°ç‚¹
ctx.arc(x, y, radius, startAngle, endAngle);  // ç”»åœ†å¼§

å®Œæˆè·¯å¾„:
ctx.closePath();  // é—­åˆè·¯å¾„
ctx.stroke();  // æè¾¹
ctx.fill();  // å¡«å……

ç¤ºä¾‹ - ç»˜åˆ¶ä¸‰è§’å½¢:
ctx.beginPath();
ctx.moveTo(100, 100);
ctx.lineTo(200, 200);
ctx.lineTo(100, 200);
ctx.closePath();
ctx.fill();
                """,
                "metadata": {"source": "canvas", "api": "path", "category": "basic"}
            },
            {
                "content": """
Canvas API - åŠ¨ç”»
åˆ›å»ºæµç•…çš„CanvasåŠ¨ç”»ã€‚

requestAnimationFrame:
ä½¿ç”¨requestAnimationFrameåˆ›å»ºåŠ¨ç”»å¾ªç¯ã€‚

function animate() {
    requestAnimationFrame(animate);

    // æ¸…é™¤ç”»å¸ƒ
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // ç»˜åˆ¶å†…å®¹
    drawGameObjects();

    // æ›´æ–°çŠ¶æ€
    updateGameLogic();
}

animate();

æ€§èƒ½ä¼˜åŒ–:
- åªé‡ç»˜æ”¹å˜çš„åŒºåŸŸ
- ä½¿ç”¨ç¦»å±canvas
- é¿å…é¢‘ç¹çš„çŠ¶æ€æ”¹å˜
- æ‰¹é‡ç»˜åˆ¶ç›¸åŒçš„å¯¹è±¡
                """,
                "metadata": {"source": "canvas", "api": "animation", "category": "advanced"}
            }
        ]

        documents = []
        for i, doc_data in enumerate(canvas_docs):
            documents.append(Document(
                content=doc_data["content"].strip(),
                metadata=doc_data["metadata"],
                id=f"canvas_doc_{i}"
            ))

        logger.info(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªCanvasæ–‡æ¡£")
        return documents
